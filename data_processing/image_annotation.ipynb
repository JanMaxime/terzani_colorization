{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image annotation script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will serve as a prototype to create a script to annotate all the images of Terzani collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the client library\n",
    "\n",
    "If the Google cloud vision library is not installed already, install it.\n",
    "\n",
    "If you have python environment use\n",
    "\n",
    "```shell\n",
    "pip install --upgrade google-cloud-vision\n",
    "```\n",
    "\n",
    "If you have conda environment use\n",
    "\n",
    "```shell\n",
    "conda install -c conda-forge google-cloud-vision\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing other libraries\n",
    "\n",
    "Install `dotenv` to get the environment variables\n",
    "\n",
    "If you have python environment use\n",
    "\n",
    "```shell\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "If you have conda environment use\n",
    "\n",
    "```shell\n",
    "conda install -c conda-forge python-dotenvn\n",
    "```\n",
    "\n",
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the standard libraries\n",
    "import os, io, pickle, random, json\n",
    "## Import Vison API related libraries\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "## Import dotenv library to get environment variables\n",
    "from dotenv import load_dotenv\n",
    "# Import urllib to read images\n",
    "import urllib.request as ur\n",
    "# Import pymango to inset data into mangodb\n",
    "import pymongo\n",
    "from tqdm import tqdm\n",
    "# \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the service account credentials to use the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_APPLICATION_CREDENTIALS = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = GOOGLE_APPLICATION_CREDENTIALS\n",
    "\n",
    "MANGO_CLIENT_URI = os.getenv('MONGO_URI')\n",
    "os.environ['MANGO_CLIENT_URI'] = MANGO_CLIENT_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Client to access the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image selection\n",
    "\n",
    "As this is a prototyping script we shall select 10 images randomly each from the color and monochrome photos (using the already created pickle files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic class to store an image and its IIIF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Terzani_Photo(object):\n",
    "    def __init__(self, iiif, photo):\n",
    "        self.iiif = iiif\n",
    "        self.photo = photo\n",
    "        \n",
    "    def get_photo_link(self):\n",
    "        return self.iiif[\"images\"][0][\"resource\"][\"@id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_of_images_per_type = 1\n",
    "\n",
    "# loading the color photos\n",
    "color_photos = pickle.load(open(\"terzani_recto_iiif_color.pickle\", \"rb\" ))\n",
    "# randomly selecting 10 images\n",
    "color_photos = random.sample(color_photos, nu_of_images_per_type)\n",
    "\n",
    "# loading the monochrome photos\n",
    "bw_photos = pickle.load(open(\"terzani_recto_iiif_color.pickle\", \"rb\" ))\n",
    "# randomly selecting 10 images\n",
    "bw_photos = random.sample(bw_photos, nu_of_images_per_type)\n",
    "\n",
    "all_photos = color_photos + bw_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str, lower: bool=True, rmv_punc: bool = True, stem: bool = True, norm: bool = True):\n",
    "    \"\"\"\n",
    "    This function accepts a string and performs preprocessing steps on it. \n",
    "    \n",
    "    :param text (str): The string or text on which the preprocessing has to be performed.\n",
    "    :param lower (bool): Default=True, indicates if the text has to be made into lower case.\n",
    "    :param rmv_punc (bool): Default=True, indicates if the punctuation should be removed in the text.\n",
    "    :param stem (bool): Default=True, indicates if the stemming should be performed on the words in the text.\n",
    "    :param norm (bool): Default=True, indicates if the words in the has to be normalised.\n",
    "    :return cleaned_text (list): The modified text is returned as list after performing the indicated operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # split into words\n",
    "    tokens = word_tokenize(text)\n",
    "    if lower:\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "    if rmv_punc:\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [w.translate(table) for w in tokens if w.translate(table) != '']\n",
    "    if stem:\n",
    "        # stemming of words\n",
    "        porter = PorterStemmer()\n",
    "        tokens = [porter.stem(word) for word in tokens]\n",
    "    cleaned_text = list(set(tokens))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:16<00:00,  8.36s/it]\n"
     ]
    }
   ],
   "source": [
    "tagged_images = dict() # The keys would be the tags, entities and objects found in the annotation and the values would be the image labels.\n",
    "annotated_images = dict() # The keys would be the image labels and the values will be the IIIF annotation, name of the country, lat,lon if there is geotag and object localization.\n",
    "failed_images = dict() # We store information about images that are failed to be annotated by google api.\n",
    "\n",
    "for img in tqdm(all_photos):\n",
    "\n",
    "    # if the image is already not present in the either annotated and failed dictionaries\n",
    "    if img.iiif[\"label\"] not in annotated_images and img.iiif[\"label\"] not in failed_images:\n",
    "\n",
    "        # get the image label\n",
    "        img_lbl = img.iiif[\"label\"]\n",
    "        img_country = None\n",
    "        # TODO: ADD COUNTRY INFORMATION OF THE IMAGE\n",
    "                \n",
    "        # reading the image\n",
    "        image_data = ur.urlopen(img.get_photo_link()).read()\n",
    "        image = types.Image(content=image_data)\n",
    "        \n",
    "        # call the goole vision api to get the annotations of various types\n",
    "        response = client.annotate_image({\n",
    "            'image': image,\n",
    "            'features': [{'type': vision.enums.Feature.Type.LANDMARK_DETECTION}, \n",
    "                         {'type': vision.enums.Feature.Type.LOGO_DETECTION},\n",
    "                         {'type': vision.enums.Feature.Type.LABEL_DETECTION},\n",
    "                         {'type': vision.enums.Feature.Type.TEXT_DETECTION},\n",
    "                         {'type': vision.enums.Feature.Type.OBJECT_LOCALIZATION},\n",
    "                         {'type': vision.enums.Feature.Type.WEB_DETECTION}],})\n",
    "        \n",
    "        # check if there is any error returned by the api\n",
    "        if response.error.code != 0:\n",
    "            failed_images[img_lbl] = {}\n",
    "            failed_images[img_lbl][\"error\"] = [response.error.code, response.error.message]\n",
    "        else:\n",
    "            # if the API call is successful\n",
    "            annotated_images[img_lbl] = {}\n",
    "        \n",
    "            # store the iiif description\n",
    "            annotated_images[img_lbl][\"iiif\"] = img.iiif\n",
    "\n",
    "            # get the list of labels\n",
    "            labels = list()\n",
    "            for lbl in response.label_annotations:\n",
    "                labels.extend(clean_text(lbl.description))\n",
    "            labels = list(set(labels))\n",
    "            \n",
    "            # Add the label and image label to the dictionary to perform search\n",
    "            for label in labels:\n",
    "                if label not in tagged_images:\n",
    "                    tagged_images[label] = []\n",
    "                if img_lbl not in tagged_images[label]:\n",
    "                    tagged_images[label].append(img_lbl)\n",
    "            \n",
    "            # get the list of web entities\n",
    "            webent = list()\n",
    "            for weben in response.web_detection.web_entities:\n",
    "                webent.extend(clean_text(weben.description))\n",
    "            webent = list(set(webent))\n",
    "            \n",
    "            # Add the web entity and image label to the dictionary to perform search\n",
    "            for web_entity in labels:\n",
    "                if web_entity not in tagged_images:\n",
    "                    tagged_images[web_entity] = []\n",
    "                if img_lbl not in tagged_images[web_entity]:\n",
    "                    tagged_images[web_entity].append(img_lbl)\n",
    "            \n",
    "\n",
    "            obj_boxes = {} # this dictionary will store the information of annotations along with bounding boxes.\n",
    "            # The key will the the name to identify the annotation and the value be a list of lists containing the top left x coordinate\n",
    "            # top left y coordinate, width and height of for the bounding box.\n",
    "            # It would be a list of list to store coordinates for different boxes for same tag\n",
    "\n",
    "            # storing the landmarks\n",
    "            landmark_info = dict() # this dictionary will store the information of landmarks which are name, latitude, longitude.\n",
    "            for lndmk in response.landmark_annotations:\n",
    "                \n",
    "                # if there are any landamrks identified, we store them in a seperate field,to access easily.\n",
    "                landmark_name = lndmk.description.lower()\n",
    "                lat, lng = lndmk.locations[0].latLng.latitude, lndmk.locations[0].latLng.longitude\n",
    "                landmark_info[landmark_name] = {\"latitude\":lndmk.locations[0].latLng.latitude, \"longitude\":lndmk.locations[0].latLng.longitude}\n",
    "                \n",
    "                \n",
    "                lndmks = clean_text(lndmk.description)\n",
    "                # we add the landmarks and image label to the dictionary to perform search\n",
    "                for land_mark in lndmks:\n",
    "                    if land_mark not in tagged_images:\n",
    "                        tagged_images[land_mark] = []\n",
    "                    if img_lbl not in tagged_images[land_mark]:\n",
    "                        tagged_images[land_mark].append(img_lbl)\n",
    "                \n",
    "                # storing the landmarks with bounding boxes \n",
    "                lndmk_desc = frozenset(lndmks)\n",
    "                if lndmk_desc not in obj_boxes:\n",
    "                    obj_boxes[lndmk_desc] = list()\n",
    "                ulx, uly, box_width, box_height = None, None, None, None\n",
    "                ulx, uly = lndmk.bounding_poly.vertices[0].x, lndmk.bounding_poly.vertices[0].y\n",
    "                box_width = lndmk.bounding_poly.vertices[1].x - lndmk.bounding_poly.vertices[0].x\n",
    "                box_height = lndmk.bounding_poly.vertices[3].y - lndmk.bounding_poly.vertices[0].y\n",
    "                lat, lng = lndmk.locations[0].latLng.latitude, lndmk.locations[0].latLng.longitude\n",
    "                if (ulx and uly and box_width and box_height and lat and lng) is not None:\n",
    "                    vert = [ulx, uly, box_width, box_height] \n",
    "                    obj_boxes[lndmk_desc].append(vert)    \n",
    "\n",
    "            for lgo in response.logo_annotations:\n",
    "                \n",
    "                logos = clean_text(lgo.description)\n",
    "                # we add the logo names and image label to the dictionary to perform search\n",
    "                for lgo_name in logos:\n",
    "                    if lgo_name not in tagged_images:\n",
    "                        tagged_images[lgo_name] = []\n",
    "                    if img_lbl not in tagged_images[lgo_name]:\n",
    "                        tagged_images[lgo_name].append(img_lbl)\n",
    "                        \n",
    "                lgo_desc = frozenset(logos)\n",
    "                if lgo_desc not in obj_boxes:\n",
    "                    obj_boxes[lgo_desc] = list()\n",
    "                ulx, uly, box_width, box_height = None, None, None, None\n",
    "                ulx, uly = lgo.bounding_poly.vertices[0].x, lgo.bounding_poly.vertices[0].y\n",
    "                box_width = abs(lgo.bounding_poly.vertices[1].x - lgo.bounding_poly.vertices[0].x)\n",
    "                box_height = abs(lgo.bounding_poly.vertices[3].y - lgo.bounding_poly.vertices[0].y)\n",
    "                if (ulx and uly and box_width and box_height) is not None:\n",
    "                    vert = [ulx, uly, box_width, box_height]\n",
    "                    obj_boxes[lgo_desc].append(vert)\n",
    "\n",
    "            if len(response.localized_object_annotations) > 0:\n",
    "                img_width, img_height = img.iiif[\"width\"], img.iiif[\"height\"]\n",
    "            for lobj in response.localized_object_annotations:\n",
    "                \n",
    "                objects = clean_text(lobj.name)  \n",
    "                # we add the object names and image label to the dictionary to perform search\n",
    "                for obj_name in objects:\n",
    "                    if obj_name not in tagged_images:\n",
    "                        tagged_images[obj_name] = []\n",
    "                    if img_lbl not in tagged_images[obj_name]:\n",
    "                        tagged_images[obj_name].append(img_lbl)\n",
    "                \n",
    "                lobj_name = frozenset(objects)\n",
    "                if lobj_name not in obj_boxes:\n",
    "                    obj_boxes[lobj_name] = list()\n",
    "                ulx, uly, box_width, box_height = None, None, None, None\n",
    "                ulx, uly = lobj.bounding_poly.normalized_vertices[0].x * img_width, lobj.bounding_poly.normalized_vertices[0].y * img_height\n",
    "                box_width = (lobj.bounding_poly.normalized_vertices[1].x - lobj.bounding_poly.normalized_vertices[0].x) * img_width\n",
    "                box_height = (lobj.bounding_poly.normalized_vertices[3].y - lobj.bounding_poly.normalized_vertices[0].y) * img_height\n",
    "                if (ulx and uly and box_width and box_height) is not None:\n",
    "                    vert = [ulx, uly, box_width, box_height]\n",
    "                    obj_boxes[lobj_name].append(vert)\n",
    "\n",
    "            for txt in response.text_annotations:\n",
    "                modified_text = txt.description.replace(\".\", \"_\").lower()\n",
    "                # we add the text and image label to the dictionary to perform search\n",
    "                if modified_text not in tagged_images:\n",
    "                    tagged_images[modified_text] = []\n",
    "                if img_lbl not in tagged_images[modified_text]:\n",
    "                        tagged_images[modified_text].append(img_lbl)    \n",
    "                \n",
    "                # the text identified on the images in not cleaned to store the original information.\n",
    "                if modified_text not in obj_boxes:\n",
    "                    obj_boxes[modified_text] = list()\n",
    "                ulx, uly, box_width, box_height = None, None, None, None\n",
    "                ulx, uly = txt.bounding_poly.vertices[0].x, txt.bounding_poly.vertices[0].y\n",
    "                box_width = abs(txt.bounding_poly.vertices[1].x - txt.bounding_poly.vertices[0].x)\n",
    "                box_height = abs(txt.bounding_poly.vertices[3].y - txt.bounding_poly.vertices[0].y)\n",
    "                if (ulx and uly and box_width and box_height) is not None:\n",
    "                    vert = [ulx, uly, box_width, box_height]\n",
    "                    obj_boxes[modified_text].append(vert)\n",
    "\n",
    "            # store the generated object boxes into the dictionary.\n",
    "            annotated_images[img_lbl][\"obj_boxes\"] = obj_boxes\n",
    "            \n",
    "            # store the generated land mark information into the dictionary.\n",
    "            annotated_images[img_lbl][\"landmark_info\"] = landmark_info\n",
    "            \n",
    "            # store the generated land mark information into the dictionary.\n",
    "            annotated_images[img_lbl][\"country\"] = img_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dictionaries to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pant': ['F25_73_recto'],\n",
       " 'person': ['F25_73_recto', 'T32_3_recto'],\n",
       " 'bag': ['F25_73_recto'],\n",
       " 'luggag': ['F25_73_recto'],\n",
       " 'top': ['F25_73_recto'],\n",
       " 'footwear': ['F25_73_recto'],\n",
       " 'l1多相融中經_\\n': ['F25_73_recto'],\n",
       " 'l1': ['F25_73_recto'],\n",
       " '多': ['F25_73_recto'],\n",
       " '相融': ['F25_73_recto'],\n",
       " '中': ['F25_73_recto'],\n",
       " '經': ['F25_73_recto'],\n",
       " '_': ['F25_73_recto'],\n",
       " 'stock': ['T32_3_recto'],\n",
       " 'monochrom': ['T32_3_recto'],\n",
       " 'photograph': ['T32_3_recto'],\n",
       " 'famili': ['T32_3_recto'],\n",
       " 'blackandwhit': ['T32_3_recto'],\n",
       " 'snapshot': ['T32_3_recto'],\n",
       " 'room': ['T32_3_recto'],\n",
       " 'photographi': ['T32_3_recto'],\n",
       " 'peopl': ['T32_3_recto'],\n",
       " 'cloth': ['T32_3_recto'],\n",
       " 'hat': ['T32_3_recto']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F25_73_recto': {'iiif': {'@id': 'http://dl.cini.it/oa/items/65176/canvas.json',\n",
       "   'label': 'F25_73_recto',\n",
       "   '@type': 'sc:Canvas',\n",
       "   'width': 1411,\n",
       "   'height': 1976,\n",
       "   'images': [{'@id': 'http://dl.cini.it/oa/files/64136/anno.json',\n",
       "     'motivation': 'sc:painting',\n",
       "     '@type': 'oa:Annotation',\n",
       "     'resource': {'@id': 'http://dl.cini.it/files/original/2d738bb20548a5ed13d35b8d854326ab.jpg',\n",
       "      '@type': 'dctypes:Image',\n",
       "      'format': 'image/jpeg',\n",
       "      'width': 1411,\n",
       "      'height': 1976,\n",
       "      'service': {'@id': 'http://dl.cini.it:8080/digilib/Scaler/IIIF/2d738bb20548a5ed13d35b8d854326ab.jpg',\n",
       "       '@context': 'http://iiif.io/api/image/2/context.json',\n",
       "       'profile': 'http://iiif.io/api/image/2/level2.json'}},\n",
       "     'on': 'http://dl.cini.it/oa/items/65176/canvas.json'}],\n",
       "   'metadata': [{'label': 'Identifier',\n",
       "     'value': '8063be1d-985f-487f-a2ed-2f6b4d8cdb91'},\n",
       "    {'label': 'notes', 'value': 'F25_73_recto'},\n",
       "    {'label': 'originalFileName', 'value': 'F25_73_recto.jpg'},\n",
       "    {'label': 'filename', 'value': '145.jpg'},\n",
       "    {'label': 'fileMD5', 'value': '4a8cdcbe9cb7ba7a11fc793ff47caf8c'}],\n",
       "   'otherContent': [{'@id': 'http://dl.cini.it/oa/items/65176/annolist.json',\n",
       "     '@type': 'sc:AnnotationList'}]},\n",
       "  'obj_boxes': {frozenset({'pant'}): [[352.30188269913197,\n",
       "     997.7589139938354,\n",
       "     389.63529132306576,\n",
       "     811.3735265731812]],\n",
       "   frozenset({'person'}): [[323.7687552422285,\n",
       "     227.80417919158936,\n",
       "     525.4054771214724,\n",
       "     1636.817141532898],\n",
       "    [332.5386545062065,\n",
       "     285.2628210783005,\n",
       "     479.5440890789032,\n",
       "     1557.1787534952164],\n",
       "    [894.8522987365723,\n",
       "     604.9897148609161,\n",
       "     271.9281666278839,\n",
       "     824.5832998752594]],\n",
       "   frozenset({'bag',\n",
       "              'luggag'}): [[214.26865512132645,\n",
       "     661.2609405517578,\n",
       "     319.11292308568954,\n",
       "     431.63036584854126], [392.46505546569824,\n",
       "     441.22653901576996,\n",
       "     435.5365437865257,\n",
       "     653.062330365181], [40.388209104537964,\n",
       "     973.3267076015472,\n",
       "     270.79621471464634,\n",
       "     453.04401993751526]],\n",
       "   frozenset({'top'}): [[386.169714897871,\n",
       "     431.5238643884659,\n",
       "     450.60205695033073,\n",
       "     677.9966276884079]],\n",
       "   frozenset({'footwear'}): [[508.1606458723545,\n",
       "     1733.4542756080627,\n",
       "     222.8371087014675,\n",
       "     108.04553985595703]],\n",
       "   frozenset({'bag'}): [[213.33482685685158,\n",
       "     706.7466335296631,\n",
       "     306.2479427754879,\n",
       "     393.2384886741638]],\n",
       "   'l1多相融中經_\\n': [[1100, 292, 87, 480]],\n",
       "   'l1': [[1116, 292, 71, 146]],\n",
       "   '多': [[1111, 440, 71, 58]],\n",
       "   '相融': [[1120, 517, 48, 47]],\n",
       "   '中': [[1105, 598, 71, 92]],\n",
       "   '經': [[1102, 692, 71, 58]],\n",
       "   '_': [[1133, 765, 7, 7]]},\n",
       "  'landmark_info': {},\n",
       "  'country': None},\n",
       " 'T32_3_recto': {'iiif': {'@id': 'http://dl.cini.it/oa/items/70112/canvas.json',\n",
       "   'label': 'T32_3_recto',\n",
       "   '@type': 'sc:Canvas',\n",
       "   'width': 3847,\n",
       "   'height': 3128,\n",
       "   'images': [{'@id': 'http://dl.cini.it/oa/files/69072/anno.json',\n",
       "     'motivation': 'sc:painting',\n",
       "     '@type': 'oa:Annotation',\n",
       "     'resource': {'@id': 'http://dl.cini.it/files/original/a925c278d147717d09649d58e02db587.jpg',\n",
       "      '@type': 'dctypes:Image',\n",
       "      'format': 'image/jpeg',\n",
       "      'width': 3847,\n",
       "      'height': 3128,\n",
       "      'service': {'@id': 'http://dl.cini.it:8080/digilib/Scaler/IIIF/a925c278d147717d09649d58e02db587.jpg',\n",
       "       '@context': 'http://iiif.io/api/image/2/context.json',\n",
       "       'profile': 'http://iiif.io/api/image/2/level2.json'}},\n",
       "     'on': 'http://dl.cini.it/oa/items/70112/canvas.json'}],\n",
       "   'metadata': [{'label': 'Identifier',\n",
       "     'value': '49e69bb5-b4e9-4326-88c5-05f1d0987ca1'},\n",
       "    {'label': 'notes', 'value': 'T32_3_recto'},\n",
       "    {'label': 'originalFileName', 'value': 'T32_3_recto.jpg'},\n",
       "    {'label': 'filename', 'value': '5.jpg'},\n",
       "    {'label': 'fileMD5', 'value': '7012d9aa3e15f296e257c393f75940aa'}],\n",
       "   'otherContent': [{'@id': 'http://dl.cini.it/oa/items/70112/annolist.json',\n",
       "     '@type': 'sc:AnnotationList'}]},\n",
       "  'obj_boxes': {frozenset({'person'}): [[1177.407035022974,\n",
       "     1244.2192075252533,\n",
       "     1227.4258752167225,\n",
       "     1721.3774664402008],\n",
       "    [146.60142788663507,\n",
       "     942.917093038559,\n",
       "     1451.14771675691,\n",
       "     2048.3565561771393],\n",
       "    [2601.811816394329,\n",
       "     542.4079705476761,\n",
       "     978.1024630665779,\n",
       "     2397.472388625145],\n",
       "    [1123.8783139884472,\n",
       "     1342.6159794330597,\n",
       "     1265.784169882536,\n",
       "     1607.1423337459564]],\n",
       "   frozenset({'cloth'}): [[2641.7591536045074,\n",
       "     873.3603074550629,\n",
       "     916.231154024601,\n",
       "     998.148505449295],\n",
       "    [2609.5419465899467,\n",
       "     1700.327175617218,\n",
       "     946.6029621362686,\n",
       "     1213.6666460037231],\n",
       "    [3432.422927558422,\n",
       "     923.937068939209,\n",
       "     273.1518273949623,\n",
       "     1958.1106204986572]],\n",
       "   frozenset({'hat'}): [[1884.8116293251514,\n",
       "     803.4429404735565,\n",
       "     408.6906214058399,\n",
       "     413.3965048789978]]},\n",
       "  'landmark_info': {},\n",
       "  'country': None}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tagged_images.json', 'w') as fp:\n",
    "    json.dump(tagged_images, fp, indent=4)\n",
    "    \n",
    "with open('annotated_images.json', 'w') as fp:\n",
    "    json.dump(annotated_images, fp, indent=4)\n",
    "\n",
    "if len(failed_images) > 0:\n",
    "    print(\"There are failed images\")\n",
    "    with open('failed_images.json', 'w') as fp:\n",
    "        json.dump(failed_images, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting the data into Mangodb\n",
    "\n",
    "# TODO: The insert the data into database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a client to work with mango db\n",
    "mangoclient = pymongo.MongoClient(MANGO_CLIENT_URI)\n",
    "# selecting the <terzani_photos> database\n",
    "mango_db = mangoclient[\"terzani_photos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the Image Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new collection named <sample_tagging>\n",
    "mango_tag_collection = mango_db[\"sample_taggings\"]\n",
    "# inserting the dictionary into the db\n",
    "for label, annotations in tagged_images.items():\n",
    "    mango_tag_collection.insert_one(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the Image information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new collection named <sample_annotations>\n",
    "mango_box_collection = mango_db[\"sample_annotations\"]\n",
    "# inserting the dictionary into the db\n",
    "for label, annotations in annotated_images.items():\n",
    "    mango_box_collection.insert_one(annotations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
